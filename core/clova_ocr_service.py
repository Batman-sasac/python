import requests
import uuid
import time
import json
import re
import os
from openai import OpenAI
import io  
from pdf2image import convert_from_bytes 
from pypdf import PdfReader

class CLOVAOCRService:
    def __init__(self, api_key):
        self.api_key = api_key
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.gpt_client = OpenAI(api_key=api_key) 
        self.model = "gpt-4o" 
        
        # ë„¤ì´ë²„ í´ë¡œë°” ì„¤ì • (í™˜ê²½ë³€ìˆ˜)
        self.clova_url = os.getenv("CLOVA_OCR_URL")
        self.clova_secret = os.getenv("CLOVA_OCR_SECRET")

    
    def get_estimation_message(self, files_data, secret_key):
        """
        [Service]
        - ì…ë ¥: [{'filename': '...', 'bytes': b'...'}, ...]
        - ë¡œì§: PDF(40ì´ˆ/ì¥), ì´ë¯¸ì§€(30ì´ˆ/ì¥) í•©ì‚°
        """

        print(f"ì‚¬ìš© ì¤‘ì¸ í‚¤: {self.clova_secret}")
        total_seconds = 0

        for file in files_data:
            filename = file.get('filename', '')
            file_bytes = file.get('bytes', b'')
            file_ext = filename.split('.')[-1].lower()

            if file_ext == 'pdf':
                try:
                    reader = PdfReader(io.BytesIO(file_bytes), strict=False)
                    pages = len(reader.pages)
                    # PDF: í˜ì´ì§€ë‹¹ 40ì´ˆ
                    total_seconds += (max(pages, 1) * 40)
                except Exception:
                    total_seconds += 40
            else:
                # ì´ë¯¸ì§€(jpg, png ë“±): ì¥ë‹¹ 30ì´ˆ
                total_seconds += 30

        minutes = total_seconds // 60
        seconds = total_seconds % 60
        
        if minutes > 0:
            return f"ì•½ {minutes}ë¶„ {seconds}ì´ˆ ì†Œìš” ì˜ˆì •"
        return f"ì•½ {seconds}ì´ˆ ì†Œìš” ì˜ˆì •"
    
    
    
    def extract_text_with_clova(self, file_bytes, filename):
        """ë„¤ì´ë²„ í´ë¡œë°” OCRì„ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""

        pages_text = []
        
        try:
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            raw_ext = filename.split('.')[-1].lower() if '.' in filename else 'jpg'
            

                # 2. í´ë¡œë°”ê°€ ì„ í˜¸í•˜ëŠ” í¬ë§·ìœ¼ë¡œ ë§¤í•‘ (jpeg -> jpg)
            if raw_ext in ['jpg', 'jpeg', 'jpe']:
                file_ext = 'jpg'
            elif raw_ext == 'png':
                file_ext = 'png'
            elif raw_ext == 'pdf':
                file_ext = 'pdf'
            elif raw_ext in ['tiff', 'tif']:
                file_ext = 'tiff'
            else:
                file_ext = 'jpg'  # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ jpg


            # í´ë¡œë°” OCR ìš”ì²­ ë°ì´í„° êµ¬ì„±
            request_json = {
                'images': [{'format': file_ext, 'name': 'ocr_request'}],
                'requestId': str(uuid.uuid4()),
                'version': 'V2',
                'timestamp': int(round(time.time() * 1000))
            }

            headers = {'X-OCR-SECRET': self.clova_secret}
            payload = {'message': json.dumps(request_json)}
            
            files = [('file', (filename, file_bytes, 'application/octet-stream'))]

            # í´ë¡œë°” API í˜¸ì¶œ
            response = requests.post(
                self.clova_url, 
                headers=headers, 
                data=payload, 
                files=files,
                timeout=180
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # [í•µì‹¬] í´ë¡œë°”ëŠ” PDFì˜ ê° í˜ì´ì§€ë¥¼ 'images' ë¦¬ìŠ¤íŠ¸ì˜ ê°œë³„ ìš”ì†Œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
                for image in result.get('images', []):
                    fields = image.get('fields', [])
                    if not fields:
                        pages_text.append("") # í…ìŠ¤íŠ¸ ì—†ëŠ” í˜ì´ì§€ ì²˜ë¦¬
                        continue

                    # í•œ í˜ì´ì§€ ë‚´ì˜ ë‹¨ì–´ë“¤ì„ ì¤„ë°”ê¿ˆì„ ì‚´ë ¤ í•©ì¹˜ê¸°
                    full_text = ""
                    # ì²« ë²ˆì§¸ í•„ë“œì˜ yì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì²« ì¤„ ì‹œì‘
                    last_y = fields[0]['boundingPoly']['vertices'][0]['y']
                    line_text = []

                    for field in fields:
                        current_y = field['boundingPoly']['vertices'][0]['y']
                        text = field.get('inferText', '')
                        
                        # yì¢Œí‘œ ì°¨ì´ê°€ 15ë³´ë‹¤ í¬ë©´ ì¤„ë°”ê¿ˆ(ì—”í„°) ì²˜ë¦¬
                        if abs(current_y - last_y) > 15:
                            full_text += " ".join(line_text) + "\n"
                            line_text = [text]
                            last_y = current_y
                        else:
                            # ê°™ì€ ì¤„ì´ë©´ ê³µë°±ìœ¼ë¡œ ì—°ê²°
                            line_text.append(text)
                    
                    # ë§ˆì§€ë§‰ ì¤„ê¹Œì§€ í•©ì³ì„œ í…ìŠ¤íŠ¸ ì™„ì„±
                    full_text += " ".join(line_text)
                    
                    # ì™„ì„±ëœ í•œ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸°
                    pages_text.append(full_text)
                    print(f"âœ… {len(pages_text)}í˜ì´ì§€ ì¶”ì¶œ ì™„ë£Œ")

                # ëª¨ë“  í˜ì´ì§€ê°€ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: ["1ìª½ ë‚´ìš©", "2ìª½ ë‚´ìš©", ...]
                return pages_text
            else:
                print(f"âŒ Clova API ì—ëŸ¬: {response.status_code}, {response.text}")
                return None

        except Exception as e:
            print(f"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return None
    
    def process_file(self, file_bytes, filename):
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í˜ì´ì§€ë³„ GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰"""

        total_start = time.time()
        
        # 1. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°›ìŒ)
        all_pages_text = self.extract_text_with_clova(file_bytes, filename)
        

        gpt_start = time.time()

        if not all_pages_text:
            return {"status": "error", "message": "OCR í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        pages_keywords = []

        # 2. ê° í˜ì´ì§€ë³„ë¡œ ë£¨í”„ë¥¼ ëŒë©° í‚¤ì›Œë“œ ì¶”ì¶œ
        for i, page_text in enumerate(all_pages_text):
            try:
                response = self.gpt_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system", 
                            "content": (
                                "ì œê³µëœ í…ìŠ¤íŠ¸ì—ì„œ í•™ìŠµì— í•„ìš”í•œ í•µì‹¬ ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
                                "1. 'ëª…ì‚¬'ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
                                "2. ìˆ«ìë‚˜ ì¤‘ìš”í•œ ê³ ìœ ëª…ì‚¬ë„ í¬í•¨í•˜ì„¸ìš”.\n"
                                "3. ë°˜ë“œì‹œ ['ë‹¨ì–´1', 'ë‹¨ì–´2'] í˜•íƒœì˜ JSON ë°°ì—´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."
                            )
                        },
                        {
                            "role": "user", 
                            "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ í‚¤ì›Œë“œë§Œ ë½‘ì•„ì¤˜:\n\n{page_text}"
                        }
                    ],
                    temperature=0
                )
                
                content = response.choices[0].message.content.strip()
                match = re.search(r'\[.*\]', content, re.DOTALL)
                
                if match:
                    json_str = match.group().replace("'", '"')
                    keywords = json.loads(json_str)
                else:
                    keywords = []

                pages_keywords.append(keywords)

            except Exception as e:
                print(f"í˜ì´ì§€ {i+1} GPT ì—ëŸ¬: {e}")
                pages_keywords.append([]) 

        gpt_duration = time.time() - gpt_start
        print(f"â±ï¸ [GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì†Œìš” ì‹œê°„]: {gpt_duration:.2f}ì´ˆ")
        
        total_duration = time.time() - total_start
        print(f"ğŸš€ [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì´ ì†Œìš” ì‹œê°„]: {total_duration:.2f}ì´ˆ")
        # 3. ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "status": "success",
            "pages": all_pages_text,
            "pages_keywords": pages_keywords,
            "original_text": all_pages_text[0] if all_pages_text else "",
            "keywords": pages_keywords[0] if pages_keywords else [],
            "total_duration": total_duration,
        }
