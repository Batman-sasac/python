import requests
import uuid
import time
import json
import re
import os
from openai import OpenAI
import io  
from pdf2image import convert_from_bytes 
from pypdf import PdfReader

class CLOVAOCRService:
    def __init__(self, api_key):
        self.api_key = api_key
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.gpt_client = OpenAI(api_key=api_key) 
        self.model = "gpt-4o" 
        
        # ë„¤ì´ë²„ í´ë¡œë°” ì„¤ì • (í™˜ê²½ë³€ìˆ˜)
        self.clova_url = os.getenv("CLOVA_OCR_URL")
        self.clova_secret = os.getenv("CLOVA_OCR_SECRET")

    
    def get_estimation_message(self, files_data, secret_key):
        """
        [Service]
        - ì…ë ¥: [{'filename': '...', 'bytes': b'...'}, ...]
        - ë¡œì§: PDF(40ì´ˆ/ì¥), ì´ë¯¸ì§€(30ì´ˆ/ì¥) í•©ì‚°
        """

        print(f"ì‚¬ìš© ì¤‘ì¸ í‚¤: {self.clova_secret}")
        total_seconds = 0

        for file in files_data:
            filename = file.get('filename', '')
            file_bytes = file.get('bytes', b'')
            file_ext = filename.split('.')[-1].lower()

            if file_ext == 'pdf':
                try:
                    reader = PdfReader(io.BytesIO(file_bytes), strict=False)
                    pages = len(reader.pages)
                    # PDF: í˜ì´ì§€ë‹¹ 40ì´ˆ
                    total_seconds += (max(pages, 1) * 40)
                except Exception:
                    total_seconds += 40
            else:
                # ì´ë¯¸ì§€(jpg, png ë“±): ì¥ë‹¹ 30ì´ˆ
                total_seconds += 30

        minutes = total_seconds // 60
        seconds = total_seconds % 60
        
        if minutes > 0:
            return f"ì•½ {minutes}ë¶„ {seconds}ì´ˆ ì†Œìš” ì˜ˆì •"
        return f"ì•½ {seconds}ì´ˆ ì†Œìš” ì˜ˆì •"
    
    
    
    def extract_text_with_clova(self, file_bytes, filename):
        """ë„¤ì´ë²„ í´ë¡œë°” OCRì„ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ.
        file_bytes: ì›ë³¸ ë˜ëŠ” ocr_appì—ì„œ cropëœ ì˜ë¦° ì´ë¯¸ì§€ bytes (ì¢Œí‘œ ì ìš© í›„ ë„˜ì–´ì˜´).
        """
        pages_text = []
        
        try:
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            raw_ext = filename.split('.')[-1].lower() if '.' in filename else 'jpg'
            

                # 2. í´ë¡œë°”ê°€ ì„ í˜¸í•˜ëŠ” í¬ë§·ìœ¼ë¡œ ë§¤í•‘ (jpeg -> jpg)
            if raw_ext in ['jpg', 'jpeg', 'jpe']:
                file_ext = 'jpg'
            elif raw_ext == 'png':
                file_ext = 'png'
            elif raw_ext == 'pdf':
                file_ext = 'pdf'
            elif raw_ext in ['tiff', 'tif']:
                file_ext = 'tiff'
            else:
                file_ext = 'jpg'  # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ jpg


            # í´ë¡œë°” OCR ìš”ì²­ ë°ì´í„° êµ¬ì„± (langì€ message ìµœìƒìœ„, ê³µì‹ê°’: ko/ja/zh-TW)
            request_json = {
                'version': 'V2',
                'requestId': str(uuid.uuid4()),
                'timestamp': int(round(time.time() * 1000)),
                'lang': 'ko',
                'images': [{'format': file_ext, 'name': 'ocr_request'}]
            }

            headers = {'X-OCR-SECRET': self.clova_secret}
            payload = {'message': json.dumps(request_json)}
            
            files = [('file', (filename, file_bytes, 'application/octet-stream'))]

            # í´ë¡œë°” API í˜¸ì¶œ
            response = requests.post(
                self.clova_url, 
                headers=headers, 
                data=payload, 
                files=files,
                timeout=180
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # [í•µì‹¬] í´ë¡œë°”ëŠ” PDFì˜ ê° í˜ì´ì§€ë¥¼ 'images' ë¦¬ìŠ¤íŠ¸ì˜ ê°œë³„ ìš”ì†Œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
                for image in result.get('images', []):
                    fields = image.get('fields', [])
                    if not fields:
                        pages_text.append("")
                        continue

                    # --- [ì •ë ¬ ë¡œì§ ì‹œì‘] ---
                    # 1. ëª¨ë“  í•„ë“œë¥¼ Yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¨¼ì € ì •ë ¬ (ìœ„ -> ì•„ë˜)
                    fields.sort(key=lambda x: x['boundingPoly']['vertices'][0]['y'])

                    lines = []
                    current_line = []
                    # ì²« ì¤„ì˜ ê¸°ì¤€ Yì¢Œí‘œ ì„¤ì •
                    last_y = fields[0]['boundingPoly']['vertices'][0]['y']

                    for field in fields:
                        current_y = field['boundingPoly']['vertices'][0]['y']
                        
                        # Yì¢Œí‘œ ì°¨ì´ê°€ 15ë³´ë‹¤ í¬ë©´ ìƒˆë¡œìš´ ì¤„ë¡œ ê°„ì£¼
                        if abs(current_y - last_y) > 15:
                            # ì´ì „ ì¤„ì´ ì™„ì„±ë˜ì—ˆìœ¼ë¯€ë¡œ Xì¢Œí‘œë¡œ ì •ë ¬ (ì™¼ìª½ -> ì˜¤ë¥¸ìª½)
                            current_line.sort(key=lambda x: x['boundingPoly']['vertices'][0]['x'])
                            lines.append(current_line)
                            
                            current_line = [field]
                            last_y = current_y
                        else:
                            current_line.append(field)
                    
                    # ë§ˆì§€ë§‰ ì¤„ ì²˜ë¦¬
                    current_line.sort(key=lambda x: x['boundingPoly']['vertices'][0]['x'])
                    lines.append(current_line)

                    # 2. ì •ë ¬ëœ ì¤„ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
                    full_page_text = ""
                    for line in lines:
                        line_text = " ".join([f.get('inferText', '') for f in line])
                        full_page_text += line_text + "\n"

                    pages_text.append(full_page_text.strip())
                    print(f"âœ… {len(pages_text)}í˜ì´ì§€ ì¶”ì¶œ ë° ì •ë ¬ ì™„ë£Œ")
                    # --- [ì •ë ¬ ë¡œì§ ë] ---

                return pages_text
            else:
                print(f"âŒ Clova API ì—ëŸ¬: {response.status_code}, {response.text}")
                return None
        except Exception as e:
            print(f"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return None


    
    def process_file(self, file_bytes, filename):
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í˜ì´ì§€ë³„ GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰.
        file_bytes: ocr_appì—ì„œ ì „ë‹¬ â€” crop ì ìš© ì‹œ ì˜ë¦° ì´ë¯¸ì§€ bytesë§Œ ë„˜ì–´ì˜´.
        """
        total_start = time.time()
        # 1. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì „ë‹¬ë°›ì€ ì´ë¯¸ì§€ = ì›ë³¸ ë˜ëŠ” ì˜ë¦° ì˜ì—­ë§Œ)
        all_pages_text = self.extract_text_with_clova(file_bytes, filename)
        

        gpt_start = time.time()

        if not all_pages_text:
            return {"status": "error", "message": "OCR í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        all_keywords = []

        # 2. ê° í˜ì´ì§€ë³„ë¡œ ë£¨í”„ë¥¼ ëŒë©° í‚¤ì›Œë“œ ì¶”ì¶œ
        for i, page_text in enumerate(all_pages_text):
            try:
                response = self.gpt_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system", 
                            "content": (
                                "ì œê³µëœ í…ìŠ¤íŠ¸ì—ì„œ í•™ìŠµì— í•„ìš”í•œ í•µì‹¬ ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
                                "1. 'ëª…ì‚¬'ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
                                "2. ìˆ«ìë‚˜ ì¤‘ìš”í•œ ê³ ìœ ëª…ì‚¬ë„ í¬í•¨í•˜ì„¸ìš”.\n"
                                "3. ë°˜ë“œì‹œ ['ë‹¨ì–´1', 'ë‹¨ì–´2'] í˜•íƒœì˜ JSON ë°°ì—´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n"
                                "4. ì¡°ì‚¬, í˜•ìš©ì‚¬ë„ ì œì™¸í•˜ê³  ëª…ì‚¬ë§Œ í¬í•¨í•˜ì„¸ìš”."
                            )
                        },
                        {
                            "role": "user", 
                            "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ í‚¤ì›Œë“œë§Œ ë½‘ì•„ì¤˜:\n\n{page_text}"
                        }
                    ],
                    temperature=0
                )
                
                content = response.choices[0].message.content.strip()
                match = re.search(r'\[.*\]', content, re.DOTALL)
                
                if match:
                    json_str = match.group().replace("'", '"')
                    keywords = json.loads(json_str)
                else:
                    keywords = []

                all_keywords.append(keywords)

            except Exception as e:
                print(f"í˜ì´ì§€ {i+1} GPT ì—ëŸ¬: {e}")
                all_keywords.append([]) 

        gpt_duration = time.time() - gpt_start
        print(f"â±ï¸ [GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì†Œìš” ì‹œê°„]: {gpt_duration:.2f}ì´ˆ")
        
        total_duration = time.time() - total_start
        page_count = len(all_pages_text)
        print(f"ğŸš€ [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì´ ì†Œìš” ì‹œê°„]: {total_duration:.2f}ì´ˆ, í˜ì´ì§€ ìˆ˜: {page_count}")
        # 3. ìµœì¢… ê²°ê³¼ ë°˜í™˜
        # í”„ë¡ íŠ¸(`front/src/api/ocr.ts`)ëŠ” ë‹¤ìŒ ìš°ì„ ìˆœìœ„ë¡œ ë°ì´í„°ë¥¼ ì‚¬ìš©:
        # 1) inner.pagesê°€ ë°°ì—´ì´ë©´ ê° í˜ì´ì§€ì˜ original_text/keywordsë¥¼ í•©ì³ ì‚¬ìš©
        # 2) ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ original_text, keywords ë‹¨ì¼ í•„ë“œë¥¼ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜)
        #
        # ì—¬ê¸°ì„œëŠ” ë©€í‹° í˜ì´ì§€ë¥¼ ì •ì‹ ì§€ì›í•˜ê¸° ìœ„í•´ pages ë°°ì—´ì„ ë‚´ë ¤ì¤€ë‹¤.
        return {
            "status": "success",
            "pages": [
                {
                    "original_text": text,
                    "keywords": keywords,
                }
                for text, keywords in zip(all_pages_text, all_keywords)
            ],
            "page_count": page_count,
            "total_duration": total_duration,
        }
